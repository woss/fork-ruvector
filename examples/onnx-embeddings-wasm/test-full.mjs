#!/usr/bin/env node
/**
 * Full end-to-end test with model download
 *
 * Downloads all-MiniLM-L6-v2 and runs embedding tests
 */

import { ModelLoader, MODELS, DEFAULT_MODEL } from './loader.js';
import {
    WasmEmbedder,
    WasmEmbedderConfig,
    cosineSimilarity,
} from './pkg/ruvector_onnx_embeddings_wasm.js';

console.log('ğŸ§ª RuVector ONNX Embeddings WASM - Full E2E Test\n');
console.log('='.repeat(60));

// List available models
console.log('\nğŸ“¦ Available Models:');
ModelLoader.listModels().forEach(m => {
    const isDefault = m.id === DEFAULT_MODEL ? ' â­ DEFAULT' : '';
    console.log(`  â€¢ ${m.id} (${m.dimension}d, ${m.size})${isDefault}`);
    console.log(`    ${m.description}`);
});

console.log('\n' + '='.repeat(60));
console.log(`\nğŸ”„ Loading model: ${DEFAULT_MODEL}...\n`);

// Load model with progress
const loader = new ModelLoader({
    cache: false, // Disable cache for testing
    onProgress: ({ loaded, total, percent }) => {
        process.stdout.write(`\r  Progress: ${percent}% (${(loaded/1024/1024).toFixed(1)}MB / ${(total/1024/1024).toFixed(1)}MB)`);
    }
});

try {
    const { modelBytes, tokenizerJson, config } = await loader.loadModel(DEFAULT_MODEL);
    console.log('\n');
    console.log(`  âœ… Model loaded: ${config.name}`);
    console.log(`  âœ… Model size: ${(modelBytes.length / 1024 / 1024).toFixed(2)} MB`);
    console.log(`  âœ… Tokenizer size: ${(tokenizerJson.length / 1024).toFixed(2)} KB`);

    // Create embedder
    console.log('\nğŸ”§ Creating embedder...');
    const embedderConfig = new WasmEmbedderConfig()
        .setMaxLength(config.maxLength)
        .setNormalize(true)
        .setPooling(0);

    const embedder = WasmEmbedder.withConfig(modelBytes, tokenizerJson, embedderConfig);
    console.log(`  âœ… Embedder created`);
    console.log(`  âœ… Dimension: ${embedder.dimension()}`);
    console.log(`  âœ… Max length: ${embedder.maxLength()}`);

    // Test 1: Single embedding
    console.log('\n' + '='.repeat(60));
    console.log('\nğŸ“ Test 1: Single Embedding');
    const text1 = "The quick brown fox jumps over the lazy dog.";
    console.log(`  Input: "${text1}"`);

    const start1 = performance.now();
    const embedding1 = embedder.embedOne(text1);
    const time1 = performance.now() - start1;

    console.log(`  âœ… Output dimension: ${embedding1.length}`);
    console.log(`  âœ… First 5 values: [${Array.from(embedding1.slice(0, 5)).map(v => v.toFixed(4)).join(', ')}]`);
    console.log(`  âœ… Time: ${time1.toFixed(2)}ms`);

    // Test 2: Semantic similarity
    console.log('\n' + '='.repeat(60));
    console.log('\nğŸ“ Test 2: Semantic Similarity');

    const pairs = [
        ["I love programming in Rust", "Rust is my favorite programming language"],
        ["The weather is nice today", "It's sunny outside"],
        ["I love programming in Rust", "The weather is nice today"],
        ["Machine learning is fascinating", "AI and deep learning are interesting"],
    ];

    for (const [a, b] of pairs) {
        const start = performance.now();
        const sim = embedder.similarity(a, b);
        const time = performance.now() - start;

        const label = sim > 0.5 ? 'ğŸŸ¢ Similar' : 'ğŸ”´ Different';
        console.log(`\n  "${a.substring(0, 30)}..."`);
        console.log(`  "${b.substring(0, 30)}..."`);
        console.log(`  ${label}: ${sim.toFixed(4)} (${time.toFixed(1)}ms)`);
    }

    // Test 3: Batch embedding
    console.log('\n' + '='.repeat(60));
    console.log('\nğŸ“ Test 3: Batch Embedding');

    const texts = [
        "Artificial intelligence is transforming technology.",
        "Machine learning models learn from data.",
        "Deep learning uses neural networks.",
        "Vector databases enable semantic search.",
    ];

    console.log(`  Embedding ${texts.length} texts...`);
    const start3 = performance.now();
    const batchEmbeddings = embedder.embedBatch(texts);
    const time3 = performance.now() - start3;

    const embeddingDim = embedder.dimension();
    const numEmbeddings = batchEmbeddings.length / embeddingDim;

    console.log(`  âœ… Total values: ${batchEmbeddings.length}`);
    console.log(`  âœ… Embeddings: ${numEmbeddings} x ${embeddingDim}d`);
    console.log(`  âœ… Time: ${time3.toFixed(2)}ms (${(time3/texts.length).toFixed(2)}ms per text)`);

    // Compute pairwise similarities
    console.log('\n  Pairwise similarities:');
    for (let i = 0; i < numEmbeddings; i++) {
        for (let j = i + 1; j < numEmbeddings; j++) {
            const emb_i = batchEmbeddings.slice(i * embeddingDim, (i + 1) * embeddingDim);
            const emb_j = batchEmbeddings.slice(j * embeddingDim, (j + 1) * embeddingDim);
            const sim = cosineSimilarity(emb_i, emb_j);
            console.log(`    [${i}] vs [${j}]: ${sim.toFixed(4)}`);
        }
    }

    // Summary
    console.log('\n' + '='.repeat(60));
    console.log('\nâœ… All tests passed!');
    console.log('='.repeat(60));

    console.log('\nğŸ“Š Performance Summary:');
    console.log(`  â€¢ Model: ${config.name}`);
    console.log(`  â€¢ Dimension: ${embeddingDim}`);
    console.log(`  â€¢ Single embed: ~${time1.toFixed(0)}ms`);
    console.log(`  â€¢ Batch (4 texts): ~${time3.toFixed(0)}ms`);
    console.log(`  â€¢ Throughput: ~${(1000 / (time3/texts.length)).toFixed(0)} texts/sec`);

} catch (error) {
    console.error('\nâŒ Error:', error.message);
    console.error(error.stack);
    process.exit(1);
}
